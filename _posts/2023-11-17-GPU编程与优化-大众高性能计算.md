---
layout: post
title: "[4] GPU编程与优化 大众高性能计算"
author: "wyq"
tags: GPU编程与优化 大众高性能计算
excerpt_separator: <!--more-->

---

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas tincidunt ornare nibh, non elementum augue tempus eget. Pellentesque tempus scelerisque iaculis.<!--more--> Nullam interdum ultricies nibh quis sollicitudin. Donec ornare fermentum facilisis. Ut at sem ac sem imperdiet varius a eget tortor. Nam eu augue eget orci semper maximus in eget augue. Mauris ornare, nisl ut suscipit consectetur, mi quam interdum tellus, at rutrum quam eros ultrices mi.

# CUDA Toolkit

基本开发环境

* CUDA Driver API
  * 基于句柄的底层接口，可加载二进制或汇编的kernel函数模块，可以被各种语言调用
  * cu*()
  * 编译时需添加-lcuda

* CUDA Runtime API
  * 封装Driver API，在第一次调用运行时函数时完成初始化
  * cuda*()
  * 编译时需添加-lcudart

* CUDA 库函数

编译

* NVCC编译器
  * eg. -O3; -arch
* cuobjdump
  * PTX 运行时 转换为GPU微码
  * PTX 离线 生成cubin文件（可反向汇编成SASS代码）

# CUDA 编程模型

![image-20231117210823626](C:\Users\wyq01\AppData\Roaming\Typora\typora-user-images\image-20231117210823626.png)

一个kernel对应一个grid，每个grid根据需要配置不同的block数量和thread数量

CUDA包含两个并行逻辑层

* block层 => SM
* thread层 => SP（Core）

CUDA编程七步曲

```c
cudaSetDevice(0); //获取设备；只有一个GPU/默认使用0号GPU时可省略
cudaMalloc((void**) &d_a, sizeof(float)*n); //分配显存
cudaMemcpy(d_a, a, sizeof(float)*n, cudaMemcpyHostToDevice); //数据传输H2D
gpu_kernel<<<blocks, threads>>>(***); //kernel函数
cudaMemcpy(a, d_a, sizeof(float)*n, cudaMemcpyDeviceToHost); //数据传输D2H
cudaFree(d_a); //释放显存
cudaDeviceReset(); //重置设备
```

# cuda runtime API

## 设备管理函数

```c
struct __device_builtin__cudaDeviceProp
{
    char	name[256];					//GPU型号
    size_t	totalGlobalMem;				//Global memory(B)
    size_t	sharedMemPerBlock;			//每块共享存储容量(B)
    int		regsPerBlock;				//每块寄存器数量
    int		warpSize;					//Warp size
    size_t	memPitch;					//最大内存复制步长
    int		maxThreadsPerBlock;			//每块最大线程数量
    int		maxThreadsDim[3];			//线程块三维
    int		maxGridSize[3];				//线程格三维
    
    int 	clockRate;					//计算核心时钟频率(kHz)
    size_t	totalConstMem;				//常量存储容量
    int		major;						//主计算能力（小数点前的值）
    int		minor;						//次计算能力（小数点后的值）
    
    size_t	textureAlignment;			//纹理对齐要求
    size_t	texturePitchAlignment;		//绑定到等步长内存的纹理满足的要求
    
    int		deviceOverlap;				//GPU是否支持并发内存复制和kernel执行
    int		multiProcessorCount;		//SMX数量
    int		kernelExecTimeoutEnabled;	//是否有运行时限制
    int		integrated;					//设备是否集成
    int		canMapHostMemory;			//可否对主机内存进行映射
    int		computeMode;				//计算模式
    
    int		maxTexture1D;				//最大1D纹理大小
    int		maxTexture1DLinear;			//线性内存相关的最大1D纹理大小
    ...
    int		maxTextureCubemapLayered[2];//最大立方图分层纹理维度
    
    int		maxSurface1D;				//最大1D表面大小
    ...
    int		maxSurfaceCubemapLayered[2];//最大立方图分层表面维度
    size_t	surfaceAlignment;			//表面对齐要求
    
    int		concurrentKernels;			//设备能并发的kernel数量
    int		ECCEnabled;					//是否打开ECC校验
    int		pciBusID;					//PCI总线ID
    int		pciDeviceID;				//PCI设备ID
    int		pciDomainID;				//PCI域ID
    int		tccDriver;					//是否支持TCC(Tesla集群)
    int		asyncEngineCount;			//异步引擎数量
    int		unifiedAddressing;			//主机和设备共享同一地址空间
    int		memoryClockRate;			//存储时钟频率
    
    int		memoryBusWidth;				//Global memory总线带宽
    int		l2CacheSize;				//L2 Cache大小
    int		maxThreadsPerMultiProcessor;//每个SMX驻留的最大线程数量
}
```

## 存储管理函数

```c
cudaMalloc(void **devPtr, size_t size);
    //在GPU上分配大小为size的线性存储空间，起始地址为*devPtr
cudaMallocPitch(void **devPtr, size_t *pitch, size_t width, size_t height);
    //在GPU上分配大小为pitch*height的逻辑2D线性存储空间，起始地址为*devPtr，pitch返回width对齐后的存储空间大小 => 分配的2D数组每行都对齐【不理解】
    devPtr[x] = devPtr[rowid*pitch+column];
    //计算地址
cudaFree(void *devPtr);
    //释放devPtr指向的GPU存储区域


```



<br>

_The end_



